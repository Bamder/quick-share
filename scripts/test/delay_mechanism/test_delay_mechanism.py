"""
å»¶æ—¶æœºåˆ¶æµ‹è¯•

æµ‹è¯•æ–‡ä»¶å¤ç”¨æ—¶çš„å»¶æ—¶æœºåˆ¶ï¼š
- å¤ç”¨æ–‡ä»¶ç¼“å­˜æ—¶å»¶é•¿è¿‡æœŸæ—¶é—´

ä½¿ç”¨æ–¹æ³•:
    python scripts/test/delay_mechanism/test_delay_mechanism.py
"""

import os
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

def check_venv():
    in_venv = (
        hasattr(sys, 'real_prefix') or
        (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix) or
        os.environ.get('VIRTUAL_ENV') is not None
    )
    if not in_venv:
        print("è­¦å‘Š: æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒ")
        # åœ¨éäº¤äº’å¼ç¯å¢ƒä¸­è‡ªåŠ¨ç»§ç»­
        if not sys.stdin.isatty():
            print("éäº¤äº’å¼ç¯å¢ƒï¼Œè‡ªåŠ¨ç»§ç»­...")
            return False
        try:
            if input("ç»§ç»­? (y/n): ").strip().lower() != 'y':
                sys.exit(0)
        except (EOFError, KeyboardInterrupt):
            print("è¾“å…¥å–æ¶ˆï¼Œé€€å‡ºæµ‹è¯•")
            sys.exit(0)
    return in_venv

check_venv()

from app.utils.pickup_code import DatetimeUtil
from datetime import datetime, timedelta
import logging

sys.path.insert(0, str(Path(__file__).parent.parent))
from test_utils import *

# é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
logging.basicConfig(level=logging.INFO, format='%(message)s')

logger = logging.getLogger(__name__)


def test_delay_extension():
    """æµ‹è¯•å»¶æ—¶å»¶é•¿æœºåˆ¶"""
    log_test_start("å»¶æ—¶å»¶é•¿æœºåˆ¶")

    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from app.services.cache_service import chunk_cache, file_info_cache
        from app.services.mapping_service import update_cache_expire_at
        from app.extensions import SessionLocal
        from app.models.user import User
        from app.models.file import File
        from app.models.pickup_code import PickupCode
        from app.utils.pickup_code import generate_unique_pickup_code

        db = SessionLocal()

        try:
            # 1. åˆ›å»ºæµ‹è¯•ç”¨æˆ·å’Œæ–‡ä»¶
            user = User(username="test_delay_user", password_hash="dummy_hash")
            db.add(user)
            db.flush()

            file_record = File(
                original_name="test_delay_file.txt",
                stored_name="stored_delay_file",
                size=1024,
                hash="delay_test_hash",
                mime_type="text/plain",
                uploader_id=user.id
            )
            db.add(file_record)
            db.flush()

            # 2. åˆ›å»ºåˆå§‹å–ä»¶ç ï¼ˆæ ‡è¯†ç ï¼‰
            original_lookup_code, _ = generate_unique_pickup_code(db)
            original_expire_at = DatetimeUtil.now() + timedelta(hours=1)

            pickup_code = PickupCode(
                code=original_lookup_code,
                file_id=file_record.id,
                status="waiting",
                used_count=0,
                limit_count=3,
                expire_at=original_expire_at,
                created_at=DatetimeUtil.now()
            )
            db.add(pickup_code)
            db.commit()

            # 3. è®¾ç½®åˆå§‹ç¼“å­˜æ•°æ®
            chunks = {
                0: {
                    'data': b'test_chunk_data',
                    'hash': 'test_hash',
                    'pickup_expire_at': original_expire_at,
                    'expires_at': original_expire_at,
                }
            }
            file_info = {
                'fileName': 'test_delay_file.txt',
                'fileSize': 1024,
                'mimeType': 'text/plain',
                'totalChunks': 1,
                'uploadedAt': DatetimeUtil.now(),
                'pickup_expire_at': original_expire_at,
            }

            chunk_cache.set(original_lookup_code, chunks, user.id)
            file_info_cache.set(original_lookup_code, file_info, user.id)

            # 4. éªŒè¯åˆå§‹ç¼“å­˜è®¾ç½®
            if not chunk_cache.exists(original_lookup_code, user.id):
                log_error("âœ— åˆå§‹æ–‡ä»¶å—ç¼“å­˜è®¾ç½®å¤±è´¥")
                return False

            initial_chunks = chunk_cache.get(original_lookup_code, user.id)
            initial_expire = initial_chunks[0]['expires_at']
            log_info(f"åˆå§‹è¿‡æœŸæ—¶é—´: {initial_expire}")

            # 5. åˆ›å»ºæ–°å–ä»¶ç ï¼ˆæ¨¡æ‹Ÿæ–‡ä»¶å¤ç”¨ï¼‰
            new_lookup_code, _ = generate_unique_pickup_code(db)
            new_expire_at = DatetimeUtil.now() + timedelta(hours=2)  # æ›´æ™šçš„è¿‡æœŸæ—¶é—´

            new_pickup_code = PickupCode(
                code=new_lookup_code,
                file_id=file_record.id,
                status="waiting",
                used_count=0,
                limit_count=3,
                expire_at=new_expire_at,
                created_at=DatetimeUtil.now()
            )
            db.add(new_pickup_code)
            db.commit()

            # 6. æ‰§è¡Œå»¶æ—¶å»¶é•¿ï¼ˆæ¨¡æ‹Ÿå¤ç”¨æ—¶çš„ç¼“å­˜æ›´æ–°ï¼‰
            update_cache_expire_at(original_lookup_code, new_expire_at, db, user.id)

            # 7. éªŒè¯ç¼“å­˜è¿‡æœŸæ—¶é—´å·²è¢«å»¶é•¿
            updated_chunks = chunk_cache.get(original_lookup_code, user.id)
            updated_expire = updated_chunks[0]['expires_at']

            log_info(f"æ›´æ–°åè¿‡æœŸæ—¶é—´: {updated_expire}")

            # æ£€æŸ¥è¿‡æœŸæ—¶é—´æ˜¯å¦è¢«å»¶é•¿
            if updated_expire >= new_expire_at:
                log_info("âœ“ ç¼“å­˜è¿‡æœŸæ—¶é—´æˆåŠŸå»¶é•¿")
                success = True
            else:
                log_error(f"âœ— ç¼“å­˜è¿‡æœŸæ—¶é—´æœªå»¶é•¿: {updated_expire} < {new_expire_at}")
                success = False

            # 8. æ¸…ç†æµ‹è¯•æ•°æ®
            chunk_cache.delete(original_lookup_code, user.id)
            file_info_cache.delete(original_lookup_code, user.id)

            db.query(PickupCode).filter(PickupCode.code.in_([original_lookup_code, new_lookup_code])).delete()
            db.query(File).filter(File.id == file_record.id).delete()
            db.query(User).filter(User.id == user.id).delete()
            db.commit()

            return success

        finally:
            db.close()

    except Exception as e:
        log_error(f"å»¶æ—¶å»¶é•¿æµ‹è¯•å¤±è´¥: {e}")
        return False


def run_delay_mechanism_tests():
    """è¿è¡Œå»¶æ—¶æœºåˆ¶æµ‹è¯•"""
    log_section("å»¶æ—¶æœºåˆ¶æµ‹è¯•")

    tests = [
        ("å»¶æ—¶æµ‹è¯•", [
            test_delay_extension,
        ]),
    ]

    total_passed = 0
    total_tests = 0

    for section_name, section_tests in tests:
        log_subsection(f"{section_name} ({len(section_tests)} ä¸ªæµ‹è¯•)")

        section_passed = 0
        for test_func in section_tests:
            try:
                if test_func():
                    section_passed += 1
                    total_passed += 1
                total_tests += 1
            except Exception as e:
                log_error(f"æµ‹è¯•å¼‚å¸¸: {e}")
                total_tests += 1

        log_info(f"{section_name} é€šè¿‡: {section_passed}/{len(section_tests)}")

    log_separator("æµ‹è¯•ç»“æœæ±‡æ€»")
    success_rate = (total_passed / total_tests * 100) if total_tests > 0 else 0
    log_info(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    log_info(f"é€šè¿‡æµ‹è¯•: {total_passed}")
    log_info(f"å¤±è´¥æµ‹è¯•: {total_tests - total_passed}")
    log_info(f"æˆåŠŸç‡: {success_rate:.1f}%")
    if total_passed == total_tests:
        log_success("æ‰€æœ‰å»¶æ—¶æœºåˆ¶æµ‹è¯•é€šè¿‡ï¼ğŸ‰")
    else:
        log_error("éƒ¨åˆ†å»¶æ—¶æœºåˆ¶æµ‹è¯•å¤±è´¥")

    return total_passed == total_tests


if __name__ == "__main__":
    success = run_delay_mechanism_tests()
    sys.exit(0 if success else 1)
